{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharan/.local/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-07-15 20:10:57.473465: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-15 20:11:00.989615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 20:11:05.029198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "import base64\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_load_path = 'models/sentence_transformer'\n",
    "bart_model_load_path = 'models/bart_model'\n",
    "tokenizer_load_path = 'models/tokenizer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_load_path).to(device)\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_load_path).to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained(tokenizer_load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_embeddings_from_db(conn):\n",
    "    \"\"\"Retrieves embeddings and their corresponding chunks for a specific collection name from the SQLite database.\"\"\"\n",
    "    c = conn.cursor()\n",
    "    # c.execute('''\n",
    "    #     SELECT embeddings.chunk_text, embeddings.embedding\n",
    "    #     FROM embeddings\n",
    "    #     INNER JOIN collections\n",
    "    #     ON embeddings.collection_id = collections.id\n",
    "    #     WHERE collections.collection_name = ?\n",
    "    # ''', (\"AR22\",))\n",
    "\n",
    "    c.execute(''' SELECT chunk_text,embedding FROM embeddings''')\n",
    "    rows = c.fetchall()\n",
    "\n",
    "    chunks = []\n",
    "    embeddings = []\n",
    "\n",
    "    for row in rows:\n",
    "        chunk_text, emb_str = row\n",
    "        emb = np.frombuffer(base64.b64decode(emb_str), dtype=np.float32)\n",
    "        chunks.append(chunk_text)\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    return chunks, embeddings\n",
    "\n",
    "def query_with_bart_model_with_one_chunk(chunks, embeddings, query):\n",
    "    \"\"\"Generates a query result using the BART model based on the closest chunk embeddings.\"\"\"\n",
    "    \n",
    "\n",
    "    query_embedding = model.encode(query)\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, embeddings)[0]\n",
    "\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    most_similar_chunk = chunks[most_similar_idx]\n",
    "\n",
    "    input_text = f\"Question: {query} Context: {most_similar_chunk}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    summary_ids = bart_model.generate(inputs['input_ids'].to('cuda') if torch.cuda.is_available() else inputs['input_ids'],\n",
    "                                     max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "    response = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return response\n",
    "\n",
    "    return summary\n",
    "\n",
    "def connect_to_database(db_file):\n",
    "    \"\"\"Connects to the SQLite database.\"\"\"\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    return conn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_bart_model_with_three_chucks(chunks, embeddings, query):\n",
    "    query_embedding = model.encode(query)\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, embeddings)[0]\n",
    "    \n",
    "    # Get the indices of the top 3 most similar chunks\n",
    "    top_k = 3\n",
    "    top_k_indices = np.argpartition(-similarities, top_k)[:top_k]\n",
    "\n",
    "    # Sort the top_k indices by similarity in descending order\n",
    "    top_k_indices = top_k_indices[np.argsort(-similarities[top_k_indices])]\n",
    "\n",
    "    # Get the top 3 closest chunks\n",
    "    closest_chunks = [chunks[idx] for idx in top_k_indices]\n",
    "\n",
    "    # Construct the input text using the top 3 closest chunks\n",
    "    input_text = f\"Question: {query} Context: {closest_chunks[0]} {closest_chunks[1]} {closest_chunks[2]}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate the summary\n",
    "    summary_ids = bart_model.generate(\n",
    "        inputs['input_ids'].to('cuda') if torch.cuda.is_available() else inputs['input_ids'],\n",
    "        max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_to_database(\"final.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23842"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks, embeddings = retrieve_embeddings_from_db(conn)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joint Secretary (Finance), ICAR, Shri G. P. Sharma, visited ICAR-CRIDA, Hyderabad after assuming charge on September 17, 2022. Shri N. V. R. Murthy, Chief Finance & Accounts Officer, ICAR briefed about Shri P. Sharma.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_with_bart_model_with_one_chunk(chunks,embeddings,\"who is the director of icar creda in 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joint Secretary (Finance), ICAR, Shri G. P. Sharma, visited ICAR-CRIDA, Hyderabad after assuming charge on September 17, 2022. Shri N. V. R. Murthy, Chief Finance & Accounts Officer, ICAR. Dr. M. Maheshwari, Head, Division of Crop Science proposed NRM Division, ICar, Dr. G. Ravindra Chary, Director (Acting) & Project Coordinator, AICRPDA, Y. G Shadakshari, Director of Research, UASB.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_with_bart_model_with_three_chucks(chunks,embeddings,\"who is the director of icar creda in 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
