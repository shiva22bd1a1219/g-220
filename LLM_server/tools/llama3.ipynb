{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "\n",
    "# messages=[   ]\n",
    "class VoiceAssistant:\n",
    "    def _init_(self, mic_index=2, wake_word=\"hey google\"):\n",
    "        self.MIC_INDEX = mic_index\n",
    "        self.wake_word = wake_word\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.client = Groq(api_key=\"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\")\n",
    "        self.messages = []\n",
    "        self.engine = pyttsx3.init()\n",
    "\n",
    "        self.set_voice(\"english-us\") \n",
    "\n",
    "    def listen_for_wake_word(self):\n",
    "        with sr.Microphone(device_index=self.MIC_INDEX) as source:\n",
    "            print(\"Listening for wake word...\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            while True:\n",
    "                try:\n",
    "                    audio = self.recognizer.listen(source, timeout=7, phrase_time_limit=None)\n",
    "                    text = self.recognizer.recognize_google(audio).lower()\n",
    "                    print(f\"You said: {text}\")\n",
    "                    if self.wake_word in text:\n",
    "                        print(\"Wake word detected!\")\n",
    "                        return True\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Sorry, I did not understand that.\")\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"Could not request results; {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "    def set_voice(self, voice_id):\n",
    "        voices = self.engine.getProperty('voices')\n",
    "        \n",
    "        for voice in voices:\n",
    "            if voice.id == voice_id:\n",
    "                self.engine.setProperty('voice', voice.id)\n",
    "                break\n",
    "\n",
    "\n",
    "    def listen_for_command(self):\n",
    "        with sr.Microphone(device_index=self.MIC_INDEX) as source:\n",
    "            print(\"Listening for command...\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            try:\n",
    "                audio = self.recognizer.listen(source, timeout=4, phrase_time_limit=None)\n",
    "                text = self.recognizer.recognize_google(audio)\n",
    "                print(f\"You said: {text}\")\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Sorry, I did not understand that.\")\n",
    "                return \"\"\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"Could not request results; {e}\")\n",
    "                return \"\"\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return \"\"\n",
    "\n",
    "    def get_response(self,text):\n",
    "\n",
    "        self.messages.append({\"role\":\"user\",\n",
    "                        \"content\":text})\n",
    "        \n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            \n",
    "            messages=self.messages,\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        self.messages.append({\"role\":\"system\",\"content\":chat_completion.choices[0].message.content})\n",
    "        return chat_completion.choices[0].message.content\n",
    "\n",
    "    def speak(self, text):        \n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "\n",
    "    def ai_friend(self):\n",
    "        while True:\n",
    "            if self.listen_for_wake_word():\n",
    "                while True:\n",
    "                    command = self.listen_for_command()\n",
    "                    if command.lower() == \"exit\":\n",
    "                        print(\"Goodbye!\")\n",
    "                        return \n",
    "                    response = self.get_response(command)\n",
    "                    self.speak(response)\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    assistant = VoiceAssistant()\n",
    "    assistant.ai_friend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting groq\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sharan/.local/lib/python3.11/site-packages (from groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/sharan/.local/lib/python3.11/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/sharan/.local/lib/python3.11/site-packages (from groq) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /home/sharan/.local/lib/python3.11/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/sharan/.local/lib/python3.11/site-packages (from groq) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/sharan/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: certifi in /home/sharan/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sharan/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sharan/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/sharan/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/sharan/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.18.4)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m512.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: groq\n",
      "Successfully installed groq-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm excited to share a little bit about myself!\n",
      "\n",
      "I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. My primary function is to assist users by providing helpful and informative responses to their questions, sharing knowledge, or even just chatting with them about various topics.\n",
      "\n",
      "Here are some interesting facts about me:\n",
      "\n",
      "1. **Trained on vast amounts of text data**: I've been trained on a massive dataset of text from the internet, books, and other sources. This training enables me to understand and generate human-like language.\n",
      "2. **Multilingual**: I can understand and respond in multiple languages, including but not limited to English, Spanish, French, German, Italian, Portuguese, Dutch, Russian, Chinese, and many more.\n",
      "3. **Ability to learn and adapt**: As I interact with users, I can learn from their feedback and adapt my responses accordingly. This means I can improve my responses over time to better serve my users.\n",
      "4. **Knowledge base**: I have a vast knowledge base that I can draw upon to provide information on a wide range of topics, including history, science, technology, entertainment, and more.\n",
      "5. **Conversational abilities**: I'm designed to engage in natural-sounding conversations, using context and understanding to respond to questions and topics in a way that feels like I'm having a discussion with you.\n",
      "\n",
      "Overall, I'm here to assist, inform, and entertain! If you have any questions, need help with something, or just want to chat, I'm here to help.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "messages = []\n",
    "\n",
    "for i in range(1):\n",
    "    text = \"say abt yourself\"\n",
    "    messages.append({\"role\":\"user\",\"content\":text})\n",
    "        \n",
    "    chat_completion = client.chat.completions.create(\n",
    "            \n",
    "    messages=messages,\n",
    "    model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    # messages.append({\"role\":\"system\",\"content\":chat_completion.choices[0].message.content})\n",
    "    print(chat_completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
